一，作业一

一，执行SparkPi.scala和作业一时遇到的问题
1，pom文件依赖设置
引入依赖jackson.core。应该是包冲突
<dependency>
  <groupId>com.fasterxml.jackson.core</groupId>
  <artifactId>jackson-databind</artifactId>
  <version>2.6.6</version>
</dependency>

读取文件的时候碰到一下错误：
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V

解决办法就是在下面增加guava依赖，spark里面用的版本太低。
<dependency>
  <groupId>com.google.guava</groupId>
  <artifactId>guava</artifactId>
  <version>15.0</version>
</dependency>


2，VM options设置为：
-Dspark.master=local


二，作业一代码
1，获取环境
val conf = new SparkConf().setMaster("local[2]").setAppName("invertedIndex")
val sc = new SparkContext(conf)

2，读取文件
val inputrdd = sc.textFile(data_path)

3，建立倒排索引
val inverted_index = inputrdd.map(line => {
      val strArr = line.split("\\.")
      (strArr(0),strArr(1))
    })
      //上面对每行通过'.'分割得到index和内容，然后再对数据进行flatMap将数据分割并将文件的index放到数据里面
      .flatMap(line=>{
        val index = line._1
        val content = line._2
        val content_Strip = content.stripPrefix("\"").stripSuffix("\"")
        val content_Split = content_Strip.split(" ")
        content_Split.map(word => {
          ((word,index),1)
        })
      })
      //上述之后数据变成((it,0),1)|((is,0),1)形式。然后将相同单词和文件的数据加起来
      .reduceByKey(_+_)
      //再将数据拆分成以单词为key的以index和次数为Hashmap的格式，这样做是为了reduceByKey时方便
      .map(tup=>(tup._1._1,mutable.HashMap(tup._1._2->tup._2)))
//      .map(tup=>(tup._1._1,tup._2))
      .reduceByKey(_++_)
      //上述操作之后变成这样的形式(banana,Map(2 -> 1)) 、(is,Map(2 -> 1, 1 -> 1, 0 -> 2))
      //然后再将数据进行一定的排序并存储到Array中，最后输出即可
      .map(word_map =>{
        val myStrArr = new mutable.ArrayBuffer[(String,Int)]
        val word = word_map._1
        val index_time = word_map._2
        val index_sort = index_time.keySet.toArray.sorted
        for (idx <- index_sort){
          myStrArr.append((idx,index_time(idx)))
        }
        (word,myStrArr)
      })

最终输出如下：
inverted_index.foreach(println(_))

(is,ArrayBuffer((0,2), (1,1), (2,1)))
(banana,ArrayBuffer((2,1)))
(what,ArrayBuffer((0,1), (1,1)))
(it,ArrayBuffer((0,2), (1,1), (2,1)))
(a,ArrayBuffer((2,1)))

三，作业二代码
核心是使用FileUtil.copy去复制，FileUtil.copy 会自动帮你建父目录；而且也可以递归地获取文件列表的所有文件。

  def copyFunc(copyInfo: CopyInfo, conf: Configuration): Unit ={
    val sourceFile = copyInfo.sourceFile
    val targetFile = copyInfo.targetFile
    val sourceFs = FileSystem.get(new URI(toLegalUri(sourceFile)), conf)
    val targetFs = FileSystem.get(new URI(toLegalUri(targetFile)), conf)
      FileUtil.copy(sourceFs, new Path(sourceFile),
        targetFs, new Path(targetFile),
        false, conf)
  }


另外对于简单的类可以在类中创建case class，如下：
case class CopyInfo(sourceFile: String,
                    targetFile: String)

当一个类被声名为case class的时候，scala会帮助我们做下面几件事情：
1 构造器中的参数如果不被声明为var的话，它默认的话是val类型的，但一般不推荐将构造器中的参数声明为var
2 自动创建伴生对象，同时在里面给我们实现子apply方法，使得我们在使用的时候可以不直接显示地new对象
3 伴生对象中同样会帮我们实现unapply方法，从而可以将case class应用于模式匹配，
4 实现自己的toString、hashCode、copy、equals方法
除此之此，case class与其它普通的scala类没有区别

